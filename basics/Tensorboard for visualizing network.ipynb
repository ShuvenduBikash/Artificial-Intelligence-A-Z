{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_feature = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_feature)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(max_feature, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callback for storing tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "INFO:tensorflow:Summary name embed/embeddings:0 is illegal; using embed/embeddings_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/kernel:0 is illegal; using conv1d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/bias:0 is illegal; using conv1d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_2/kernel:0 is illegal; using conv1d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_2/bias:0 is illegal; using conv1d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 17s - loss: 0.6950 - acc: 0.5991 - val_loss: 0.5370 - val_acc: 0.7680\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.5132 - acc: 0.8025 - val_loss: 0.4361 - val_acc: 0.8330\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.4523 - acc: 0.7951 - val_loss: 0.5479 - val_acc: 0.7526\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.4325 - acc: 0.7895 - val_loss: 0.5815 - val_acc: 0.7466\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.4204 - acc: 0.7502 - val_loss: 0.5628 - val_acc: 0.7496\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.3980 - acc: 0.7429 - val_loss: 0.4910 - val_acc: 0.7502\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.3826 - acc: 0.7045 - val_loss: 0.5916 - val_acc: 0.6698\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.3713 - acc: 0.6495 - val_loss: 0.6224 - val_acc: 0.6402\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.3242 - acc: 0.6630 - val_loss: 1.1755 - val_acc: 0.5018\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.3205 - acc: 0.5987 - val_loss: 0.6695 - val_acc: 0.5992\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.2868 - acc: 0.5824 - val_loss: 0.8631 - val_acc: 0.5046\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.2744 - acc: 0.5168 - val_loss: 0.8842 - val_acc: 0.4594\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.2818 - acc: 0.4644 - val_loss: 0.9706 - val_acc: 0.4044\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.2597 - acc: 0.4083 - val_loss: 1.0767 - val_acc: 0.3410\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.2188 - acc: 0.3751 - val_loss: 1.1554 - val_acc: 0.3120\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.2154 - acc: 0.3315 - val_loss: 1.4899 - val_acc: 0.2412\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 14s - loss: 0.1978 - acc: 0.2636 - val_loss: 1.3766 - val_acc: 0.2136\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.1801 - acc: 0.2010 - val_loss: 1.4755 - val_acc: 0.2024\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.1759 - acc: 0.1685 - val_loss: 1.7497 - val_acc: 0.1644\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 15s - loss: 0.1738 - acc: 0.1475 - val_loss: 1.5764 - val_acc: 0.1508\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir',\n",
    "        histogram_freq=1,\n",
    "        embeddings_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
